{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f58559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import r2_score\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from numpy import log as ln\n",
    "sns.set_style(\"darkgrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path = '/Users/mirac/Desktop/Chlorine_Project/August 18 Chlorine Review Paper/Chlorine_Review_Revisions/1-Revisions_Inactivation_Rate_Data_R1.xlsx'\n",
    "\n",
    "df = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06846d2",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967c435",
   "metadata": {},
   "source": [
    "### There are only 3 methods:\n",
    "Method 1 - chlorine decay (The code will take care of the case of k prime given or not)\n",
    "\n",
    "Method 2 - Constant Chlorine\n",
    "\n",
    "Method 3 - Given CT\n",
    "\n",
    "Method 4 - k values are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ceaccba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# REQUIRE: df consists of every data point\n",
    "# MODIFY: Break down into several dataframe and fill up the Sample ID columns\n",
    "# EFFECT: return a list with subset dataframes of the data\n",
    "def get_df_list(df):\n",
    "    df_list = []\n",
    "    ID_ind_list = df['Sample_ID'][df['Sample_ID'].notnull()].index.tolist()\n",
    "    for i in range(len(ID_ind_list)):\n",
    "        if (i != len(ID_ind_list)-1):\n",
    "            start_ind = ID_ind_list[i]\n",
    "            end_ind = ID_ind_list[i+1]\n",
    "        else:\n",
    "            start_ind = ID_ind_list[i]\n",
    "            end_ind = df.shape[0]\n",
    "\n",
    "        df_copy = df.copy()\n",
    "        df_temp = df_copy.iloc[start_ind:end_ind]\n",
    "        ID_label = df_copy.iloc[start_ind:end_ind]['Sample_ID'].unique()[0]\n",
    "        df_temp['Sample_ID'] = ID_label\n",
    "        df_temp = df_temp.reset_index(drop = True)\n",
    "        df_list.append(df_temp)\n",
    "    return df_list\n",
    "\n",
    "# Get input function variables for each method\n",
    "def get_info(df, k_is_given):\n",
    "\n",
    "    if k_is_given:\n",
    "        method = 0\n",
    "        have_k_prime_already = False\n",
    "        C_init = 0\n",
    "        const_C = 0 \n",
    "        num_pt = 0\n",
    "\n",
    "        return method, have_k_prime_already, C_init, const_C, num_pt\n",
    "\n",
    "    else: \n",
    "        # Get method\n",
    "        method = int(df['Method'][0])\n",
    "        \n",
    "        # Get k_prime\n",
    "        given_k_prime = np.isnan(df['k_prime'][0])\n",
    "        if given_k_prime == False: # is not NaN\n",
    "            have_k_prime_already = df['k_prime'][0] \n",
    "        else:\n",
    "            have_k_prime_already = False\n",
    "        \n",
    "        # Get C0\n",
    "        given_C0 = np.isnan(df['C0'][0])\n",
    "        if given_C0 == False: # is not NaN\n",
    "            C_init = float(df['C0'][0])\n",
    "        else:\n",
    "            C_init = False\n",
    "        \n",
    "        # Get constant chlorine\n",
    "        given_const_C = np.isnan(df['Constant_Chlorine'][0])\n",
    "        if given_const_C == False: # is not NaN\n",
    "            const_C = float(df['Constant_Chlorine'][0])\n",
    "        else:\n",
    "            const_C = False\n",
    "        \n",
    "        # Get num_point used\n",
    "        num_pt = int(df['Data_Points_Used'][0])\n",
    "        \n",
    "        return method, have_k_prime_already, C_init, const_C, num_pt \n",
    "\n",
    "\n",
    "# Check the coef calculated from linear regression from numpy and OLS\n",
    "# EFFECT: return True if they are the same (with difference smaller than tolerance of 1e-5) and return False if diff > tolerance\n",
    "def same_coef(coef, coef_ols):\n",
    "    diff = coef - coef_ols\n",
    "    tolerance = 1e-5\n",
    "    if (diff < tolerance):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Display summary df after extracting the coefs from np, ols, and standard errors    \n",
    "def display_summary_df(Sample_ID_list, method_list, coef_list, coef_ols_list, error_list, totalPointUsed_list):\n",
    "    \n",
    "    def modify_diff(x):\n",
    "        x = float(np.abs(x))\n",
    "        tol = 10e-6\n",
    "        if (x < tol):\n",
    "            return 0\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    summ = pd.DataFrame()\n",
    "    summ['Sample_ID'] = Sample_ID_list\n",
    "    summ['Method'] = method_list\n",
    "    summ['Coef_np'] = coef_list\n",
    "    summ['Coef_OLS'] = coef_ols_list\n",
    "    summ['Standard_Error'] = error_list\n",
    "    summ['Data_Points_Used'] = totalPointUsed_list\n",
    "    \n",
    "    summ['Diff'] = summ['Coef_np'] - summ['Coef_OLS']\n",
    "    summ['Diff'] = summ['Diff'].apply(modify_diff)\n",
    "    \n",
    "    return summ   \n",
    "\n",
    "def results(path, sheet_name):\n",
    "    df_whole = pd.read_excel(path, sheet_name) # Get each tab or sheet\n",
    "\n",
    "    if (df_whole.shape[0] == 0):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    defaultCols = [ 'Time (min)', 'C (mg/L)', 'ln(C/C0)', 'Log 10 reduction', 'N/N0',\n",
    "                    'Titer (PFU/mL)', 'CT_values', 'ln 10 reduction', 'Method', 'k_prime',\n",
    "                    'C0', 'Constant_Chlorine', 'Data_Points_Used', 'Sample_ID', 'Given_k']\n",
    "\n",
    "    extraCols = list(set(df_whole.columns) - set(defaultCols))\n",
    "    # print(extraCols) # testing\n",
    "    # display(df_whole)\n",
    "    \n",
    "    # if len(extraCols) > 0:\n",
    "    #     if (df_whole[extraCols].dropna().shape[0]) == 0:\n",
    "    #         extraCols = []\n",
    "\n",
    "    df_list = get_df_list(df_whole)\n",
    "\n",
    "    if len(extraCols) > 0:\n",
    "        extra_df_cols = extraCols + ['Sample_ID']\n",
    "        extraFilter = df_whole[extra_df_cols]\n",
    "        extraFilter.dropna(subset = ['Sample_ID'], inplace=True)\n",
    "\n",
    "    method_list = []\n",
    "    Sample_ID_list = []\n",
    "\n",
    "    for i in range(len(df_list)):\n",
    "        each_df = df_list[i] # get each subset of datapoints\n",
    "\n",
    "        k_is_given = (each_df['Given_k'].isnull()[0] == False)\n",
    "\n",
    "        if (k_is_given):\n",
    "            method_list.append(0) # Approach 0 is when k values are given\n",
    "        else:\n",
    "            method_temp = int(each_df['Method'][0])\n",
    "            method_list.append(method_temp)\n",
    "\n",
    "        Sample_ID_temp = str(each_df['Sample_ID'][0])\n",
    "        Sample_ID_list.append(Sample_ID_temp)\n",
    "\n",
    "    coef_list = []\n",
    "    coef_ols_list = []\n",
    "    error_list = []\n",
    "    totalPointUsed_list = []\n",
    "\n",
    "    for method, temp in zip(method_list, df_list): # for each paper \n",
    "        \n",
    "        k_is_given = (temp['Given_k'].isnull()[0] == False)\n",
    "        method, have_k_prime_already, C_init, const_C, num_pt = get_info(temp, k_is_given)\n",
    "\n",
    "        if (method == 1):\n",
    "            coef, coef_ols, error = chlorine_decay(temp, have_k_prime_already, C_init, num_pt)\n",
    "        elif (method == 2):\n",
    "            coef, coef_ols, error = constant_chlorine(temp, const_C, num_pt)\n",
    "        elif (method == 3):\n",
    "            coef, coef_ols, error = Given_CT(temp, num_pt)\n",
    "        elif (method == 0):\n",
    "            k_value = Given_K(temp)\n",
    "            coef = k_value\n",
    "            coef_ols = k_value\n",
    "            error = 0\n",
    "\n",
    "        coef_list.append(coef)\n",
    "        coef_ols_list.append(coef_ols)\n",
    "        error_list.append(error)\n",
    "        totalPointUsed_list.append(num_pt)\n",
    "\n",
    "    summ = display_summary_df(Sample_ID_list, method_list, coef_list, coef_ols_list, error_list, totalPointUsed_list)\n",
    "\n",
    "    if (len(extraCols) > 0):\n",
    "        if (summ.shape[0] != extraFilter.shape[0]):\n",
    "            print(\"extraCols: \", extraCols)\n",
    "            print(f\"summ shape: {summ.shape}\")\n",
    "            print(f\"extraFilter shape: {extraFilter.shape}\")\n",
    "            display(summ)\n",
    "            display(extraFilter)\n",
    "            raise ValueError(\"Dataframe summ and extraFilter have different shapes!\")\n",
    "        summ = summ.merge(extraFilter, on = 'Sample_ID', how = 'left') \n",
    "        \n",
    "    return summ\n",
    "#########################################################################################################\n",
    "\n",
    "# For Approach 3\n",
    "\n",
    "# Plot the graph: time vs ln(C/C0)\n",
    "def plot_lnC_vs_time(df):\n",
    "    fig, ax = plt.subplots(figsize = (10,6))\n",
    "    plt.scatter(df['Time (min)'], df['ln(C/C0)'], c = 'red')\n",
    "    plt.title(\"Choose points to get the k' value\", fontweight=\"bold\", fontsize = 14)\n",
    "    plt.xlabel('Time (min)', fontsize = 14); plt.ylabel('ln(C/C0)', fontsize = 14); plt.grid(True)\n",
    "    \n",
    "    for i in range(len(df['ln(C/C0)'])):\n",
    "        ax.annotate(str(i+1), (df['Time (min)'][i], df['ln(C/C0)'][i]), \n",
    "                    xytext = (df['Time (min)'][i], df['ln(C/C0)'][i]),\n",
    "                    fontsize = 14, color = \"black\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# For Approach 3 to calculate the coef of k   \n",
    "def get_k_prime_3(df, k_primes_to_use):\n",
    "    # display(df) # testing\n",
    "    x = np.array(df['Time (min)'][0:k_primes_to_use])\n",
    "    y = np.array(df['ln(C/C0)'][0:k_primes_to_use])\n",
    "    A = np.vstack([x, np.ones(len(x))]).T # Add one to x and drop the ones later\n",
    "    A = A.astype('float64') \n",
    "    k_prime_3 = float(np.linalg.lstsq(A[:, :-1], y)[0]) # use [0] to just grab the coefs  \n",
    "    \n",
    "    df_xy = pd.DataFrame({\"x_val\": x, \"y_val\": y})\n",
    "    smOLS_reault_k_prime = sm.OLS(endog= df_xy[['y_val']], exog= df_xy[['x_val']].assign(intercept=0)).fit() \n",
    "    # intercept=0 makes sure the line passes through the origin\n",
    "\n",
    "    k_prime_OLS = smOLS_reault_k_prime.params[0]\n",
    "    std_error = smOLS_reault_k_prime.bse[0]\n",
    "    \n",
    "    print(\"================================================================\")\n",
    "    print(\"Coef for k' value (OLS): \", smOLS_reault_k_prime.params[0])\n",
    "    print(\"Standard Error for k' value (OLS): \", smOLS_reault_k_prime.bse[0])\n",
    "    print(\"================================================================\")\n",
    "\n",
    "    return k_prime_3\n",
    "\n",
    "\n",
    "# Plot the Ln vs CT graph\n",
    "def plot_ln_vs_CT(df, CT_assign): #### Note: CT_assign is CT Approachg 3; just put \"CT_values_3\" during function call\n",
    "    fig, ax = plt.subplots(figsize = (10,6)) #### Note: might need to move this line before calling this function\n",
    "    plt.scatter(df[CT_assign], df['ln 10 reduction'], c = 'red')\n",
    "    for i in range(len(df[CT_assign])):\n",
    "        ax.annotate(str(i+1), (df[CT_assign][i], df['ln 10 reduction'][i]), \n",
    "                    xytext = (df[CT_assign][i], df['ln 10 reduction'][i]),\n",
    "                    fontsize = 14)\n",
    "    \n",
    "    plt.title(\"Choose CT Values\", fontweight=\"bold\", fontsize = 14)\n",
    "    plt.xlabel(CT_assign, fontsize = 14); plt.ylabel(\"ln\", fontsize = 14);plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def get_coef(df, CT_approach_num, CT, CT_to_use):\n",
    "    if (df[CT].isnull().sum() >= len(df)-1):\n",
    "        coef = 0\n",
    "    else:      \n",
    "        if (df[\"ln 10 reduction\"].isnull().sum() != 0):\n",
    "            data = df.dropna(subset = ['ln 10 reduction'])\n",
    "        else: \n",
    "            data = df.copy()\n",
    "\n",
    "        x = np.array(data[CT][0:CT_to_use])\n",
    "        y = np.array(data['ln 10 reduction'][0:CT_to_use])\n",
    "        A = np.vstack([x, np.ones(len(x))]).T # Add one to x and drop the ones later\n",
    "        \n",
    "        coef = float(np.linalg.lstsq(A[:, :-1], y)[0]) # use [0] to just grab the coefs\n",
    "    \n",
    "    return coef\n",
    "\n",
    "\n",
    "def visualize_linear_regression(X, Y, CT_approach_num, CT, coef, point_style, line_style):   \n",
    "    plt.plot(X, Y, point_style, label = CT)           # plot the data points \n",
    "    plt.plot(X, X * coef, line_style) # Plot the linear regression\n",
    "        \n",
    "    \n",
    "def get_R2(y_actual, y_pred):\n",
    "    mean_y_actual = np.mean(y_actual)\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for y_a, y_p in zip(y_actual, y_pred):\n",
    "        numerator += (y_a - y_p)**2\n",
    "        denominator += (y_a - mean_y_actual)**2\n",
    "    ratio = numerator/denominator\n",
    "    r2 = 1- ratio\n",
    "\n",
    "    return r2\n",
    "\n",
    "\n",
    "def summary(coef, C_0, CT_to_use, CT_approach_num, CT, ds):\n",
    "    ds = ds.iloc[0:CT_to_use,:]\n",
    "    \n",
    "    y_predicted_name = \"y_predicted_\" + str(CT_approach_num)\n",
    "    ds[y_predicted_name] = ds[CT] * coef\n",
    "    \n",
    "    residual_name = \"residual_\" + str(CT_approach_num)\n",
    "    ds[residual_name] = ds['ln 10 reduction'] - ds[y_predicted_name] \n",
    "    \n",
    "    # Calculate R2\n",
    "    R2 = get_R2(np.array(ds['ln 10 reduction']), np.array(ds[y_predicted_name]))\n",
    "    R2_name = \"R Square_\" + str(CT_approach_num)\n",
    "    ds[R2_name] = R2\n",
    "    \n",
    "    return ds, R2\n",
    "\n",
    "##### UPDATED ON 6/25/2022 ###########\n",
    "\n",
    "def convert_to_ln(df): \n",
    "    \n",
    "    # Case: have only Titer (PFU/mL)\n",
    "    if (df[\"Titer (PFU/mL)\"].isnull().sum() != len(df)):\n",
    "        inital_titer = df[\"Titer (PFU/mL)\"][0]\n",
    "        df[\"N/N0\"] = df[\"Titer (PFU/mL)\"]/inital_titer\n",
    "\n",
    "    # Case: have only Log 10 reduction\n",
    "    if (df[\"N/N0\"].isnull().sum() == len(df)) & (df[\"ln 10 reduction\"].isnull().sum() == len(df)) & (df[\"Log 10 reduction\"].isnull().sum() != len(df)):\n",
    "        df['ln 10 reduction'] = df['Log 10 reduction'] * math.log(10)\n",
    "        \n",
    "    # Case: have only N/N0\n",
    "    elif (df[\"N/N0\"].isnull().sum() != len(df)) & (df[\"ln 10 reduction\"].isnull().sum() == len(df)) & (df[\"Log 10 reduction\"].isnull().sum() == len(df)): \n",
    "        ln_list = [math.log(x) for x in df[\"N/N0\"]]\n",
    "        df[\"ln 10 reduction\"] = ln_list \n",
    "\n",
    "    # Case: have only ln 10 reduction\n",
    "    elif (df[\"N/N0\"].isnull().sum() == len(df)) & (df[\"ln 10 reduction\"].isnull().sum() != len(df)) & (df[\"Log 10 reduction\"].isnull().sum() == len(df)): \n",
    "        df['ln 10 reduction'] = df['ln 10 reduction'] \n",
    "    \n",
    "    # Update constrain based on paper 23 (9/15/2022)\n",
    "    # Case: have only C/C0\n",
    "    elif (df[\"ln(C/C0)\"].isnull().sum() != len(df)) & (df[\"N/N0\"].isnull().sum() == len(df)) & (df[\"ln 10 reduction\"].isnull().sum() == len(df)) & (df[\"Log 10 reduction\"].isnull().sum() == len(df)): \n",
    "        df['ln 10 reduction'] = df['ln(C/C0)']   # Heree  \n",
    "\n",
    "        \n",
    "def empty_df(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = np.nan\n",
    "    return df\n",
    "\n",
    "# Sort rows according to Time (min) for every case except for Given CT        \n",
    "def sort_row_according_to_Time(df):\n",
    "    df_sorted = df.sort_values(by = \"Time (min)\", ascending = True)\n",
    "    return df_sorted\n",
    "\n",
    "# Sort rows according to CT_values for the case of Given CT     \n",
    "def sort_row_according_to_CT(df):\n",
    "    df_sorted = df.sort_values(by = \"CT_values\", ascending = True)\n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "def find_missing_values_in_C():\n",
    "    index_list = df[df[\"C (mg/L)\"].isnull()].index.tolist()\n",
    "    # Note: index 0 would not be a missing value\n",
    "\n",
    "def drop_nan_last_rows(df):\n",
    "    row_index = np.nan\n",
    "    last_row_isnull = df[[\"C (mg/L)\"]].iloc[-1:].isnull().values[0][0]\n",
    "    if last_row_isnull == True:\n",
    "        for i in range(1,len(df)+1):\n",
    "            nan_bool = df[[\"C (mg/L)\"]].iloc[-i:].isnull().all()[0]\n",
    "            if nan_bool == True:\n",
    "                row_index = -i\n",
    "            else: \n",
    "                row_index = row_index\n",
    "        df_drop = df.iloc[row_index:, :]\n",
    "        df = pd.concat([df, df_drop]). drop_duplicates(keep = False)\n",
    "    else:\n",
    "        df = df\n",
    "    return df, row_index\n",
    "\n",
    "# Fill in missing values in C (mg/L)\n",
    "def fill_in_missing_C(dff):\n",
    "    \n",
    "    original_shape = dff.shape\n",
    "    \n",
    "    # Drop the last row(s) if there are missing values in C (mg/L)\n",
    "    dff, row_index = drop_nan_last_rows(dff)\n",
    "\n",
    "    # Shape of df after dropping the missing value(s) at the end\n",
    "    after_drop_shape = dff.shape\n",
    "\n",
    "    index_list = np.where(dff[\"C (mg/L)\"].isnull())[0].tolist()\n",
    "\n",
    "    # Get the C (mg/L) on top of each missing value\n",
    "    top_value_list = []\n",
    "    j_top = 0\n",
    "    top_index = []\n",
    "    while (j_top < len(index_list)):\n",
    "        i = index_list[j_top]\n",
    "        while (dff[[\"C (mg/L)\"]].isnull()[\"C (mg/L)\"][i]):\n",
    "            top = dff[\"C (mg/L)\"][i-1] \n",
    "            i = i - 1\n",
    "        top_index.append(i)\n",
    "        top_value_list.append(top)\n",
    "        j_top += 1\n",
    "\n",
    "    # Get the C (mg/L) right below each missing value\n",
    "    down_value_list = []\n",
    "    j_down = 0\n",
    "    down_index = []\n",
    "    while (j_down < len(index_list)):\n",
    "        i = index_list[j_down]\n",
    "        while (dff[[\"C (mg/L)\"]].isnull()[\"C (mg/L)\"][i]):\n",
    "            down = dff[\"C (mg/L)\"][i+1] \n",
    "            i = i + 1\n",
    "        down_index.append(i)\n",
    "        down_value_list.append(down)\n",
    "        j_down += 1\n",
    "\n",
    "    # Get the time before and after each missing value\n",
    "    top_time = []\n",
    "    down_time = []\n",
    "    missing_time_list = []\n",
    "    for t, d, m in zip(top_index, down_index, index_list):\n",
    "        top_time.append(dff [\"Time (min)\"][t])\n",
    "        down_time.append(dff [\"Time (min)\"][d])\n",
    "        missing_time_list.append(dff[\"Time (min)\"][m])\n",
    "\n",
    "    # Summary\n",
    "    view_dict = {\"index\": index_list,\n",
    "         \"missing_time\": missing_time_list,\n",
    "         \"top\": top_value_list,\n",
    "         \"top_time_index\": top_index,\n",
    "         \"top_time\": top_time,\n",
    "         \"down\": down_value_list,\n",
    "         \"down_time_index\": down_index,\n",
    "         \"down_time\": down_time}\n",
    "\n",
    "    # Apply y = mx + b to get the missing C (mg/L)\n",
    "    missing_C_list = []\n",
    "    for i, missing_t in enumerate(missing_time_list):\n",
    "        x1 = top_time[i]\n",
    "        y1 = top_value_list[i]\n",
    "\n",
    "        x2 = down_time[i]\n",
    "        y2 = down_value_list[i]\n",
    "\n",
    "        slope = (y2-y1)/(x2-x1)\n",
    "        y = slope*(missing_t - x1) + y1\n",
    "        missing_C_list.append(y)\n",
    "    \n",
    "    fill = pd.DataFrame(index =dff[[\"C (mg/L)\"]].index[dff[[\"C (mg/L)\"]].isnull().any(axis=1)], data= missing_C_list, columns=[\"C (mg/L)\"])\n",
    "    dff = dff.fillna(fill)\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3e938",
   "metadata": {},
   "source": [
    "# Given K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a11c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If k values are given, one data point should only have one k value (thus return index 0)\n",
    "def Given_K(df):\n",
    "    return df['Given_k'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e6e31",
   "metadata": {},
   "source": [
    "# Chlorine Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c13ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Main Function: Chlorine Decay #########################################################################################\n",
    "\n",
    "# NOTE: \n",
    "# have_k_prime_already = False if k_prime is not given\n",
    "# have_k_prime_already is number if k_prime is given\n",
    "\n",
    "def chlorine_decay(df, have_k_prime_already, C_init, CT_to_use):\n",
    "    \n",
    "    # Fill in missing values if there is any in C (mg/L)\n",
    "    if (df[\"C (mg/L)\"].isnull().sum() == len(df)) | (df[\"C (mg/L)\"].isnull().sum() == 0):\n",
    "        pass\n",
    "    else: \n",
    "        df = fill_in_missing_C(df)\n",
    "\n",
    "    if have_k_prime_already == False:\n",
    "        # Will use columns: Time (min), ln(C/C0), log 10 reduction + ln 10 reduction + k_ + k_lag + k_variation + CT_values\n",
    "        df[\"ln(C/C0)\"] = np.log(df[\"C (mg/L)\"].astype('float') / df[\"C (mg/L)\"][0])\n",
    "\n",
    "    ############################ Calculate k prime for Approcah 1, 2, 3 ##########################################\n",
    "\n",
    "    if have_k_prime_already != False :\n",
    "        k_prime_3 = have_k_prime_already\n",
    "        \n",
    "    # Get C0\n",
    "    # Note: Do NOT put only the initial conc in C (mg/L) column because the code will drop rows with missing conc\n",
    "    if (df[\"CT_values\"].isnull().sum() == len(df)) & (df[\"C (mg/L)\"].isnull().sum() != len(df)):\n",
    "        C_0 = df['C (mg/L)'][0]\n",
    "        \n",
    "    if (df[\"CT_values\"].isnull().sum() == len(df)) & (df[\"C (mg/L)\"].isnull().sum() == len(df)):\n",
    "        C_0 = C_init\n",
    "\n",
    "    chlorine = df['C (mg/L)']\n",
    "    time = df['Time (min)']\n",
    "    # Approach 1 (Do not use this approach because too much variation)\n",
    "#     CT_values_1 = []; CT_values_1.append(0); k_prime_values_1 = []; delta_ts = []\n",
    "#     sum_CT = 0; i = 0\n",
    "#     while i+1 < len(time):\n",
    "#         #find k value\n",
    "#         delta_t = time[i+1]-time[i]\n",
    "#         #check that times are correct: delta_ts.append(delta_t)\n",
    "#         k_prime = abs(-ln(chlorine[i+1]/chlorine[i])/(delta_t))\n",
    "#         k_prime_values_1.append(k_prime)\n",
    "#         #find CT\n",
    "#         sum_CT = sum_CT + (chlorine[i]/k_prime)*(1-np.exp(-k_prime*(delta_t)))\n",
    "#         CT_values_1.append(sum_CT)\n",
    "#         i = i+1\n",
    "\n",
    "#     df[\"CT_values_1\"] = CT_values_1\n",
    "    df[\"CT_values_1\"] = np.nan\n",
    "    \n",
    "    # Approach 2 (Only use this approach when k' is not provided)\n",
    "    # We either assume the chlorine is constant or use the trapezoid calculation\n",
    "    CT_values_2 = []; CT_values_2.append(0)\n",
    "    sum_CT = 0; j = 0\n",
    "    while j+1 < len(time):\n",
    "        delta_t = time[j+1]-time[j]\n",
    "        sum_CT = sum_CT  + (chlorine[j] + chlorine[j+1])/2*delta_t\n",
    "        CT_values_2.append(sum_CT)\n",
    "        j = j+1\n",
    "    if have_k_prime_already == False :\n",
    "        df[\"CT_values_2\"] = CT_values_2\n",
    "    else: \n",
    "        df[\"CT_values_2\"] = np.nan\n",
    "\n",
    "    # Approach 3 (Always use this approach when k' is provided)\n",
    "    if have_k_prime_already != False :\n",
    "        df[\"CT_values_3\"] = (C_0/k_prime_3)*(1-np.exp(-k_prime_3* df['Time (min)']))\n",
    "        CT_approach_num = 3\n",
    "        CT = \"CT_values_3\"\n",
    "    else: \n",
    "        df[\"CT_values_3\"] = np.nan\n",
    "        CT_approach_num = 2\n",
    "        CT = \"CT_values_2\"\n",
    "\n",
    "    # Convert to ln 10 reduction\n",
    "    convert_to_ln(df)\n",
    "\n",
    "    # Sort by Time (min) column\n",
    "    df = sort_row_according_to_Time(df)\n",
    "       \n",
    "    coef_list = []; R2_list = []\n",
    "\n",
    "    coef = get_coef(df, CT_approach_num, CT, CT_to_use)\n",
    "\n",
    "    coef_list.append(coef)\n",
    "    \n",
    "    X = np.array(df[CT])\n",
    "    Y = np.array(df['ln 10 reduction'])\n",
    "    \n",
    "    # Modified the conditions on 3/4/2023\n",
    "    if (((CT_approach_num == 2) & (coef !=0)) | ((CT_approach_num == 3) & (coef !=0))):   \n",
    "        df_xy = pd.DataFrame({\"x_val\": X[0:CT_to_use], \"y_val\": Y[0:CT_to_use]})\n",
    "        smOLS_reault = sm.OLS(endog= df_xy[['y_val']], exog= df_xy[['x_val']].assign(intercept=0)).fit()\n",
    "\n",
    "        coef_ols = smOLS_reault.params[0]\n",
    "        error = smOLS_reault.bse[0]\n",
    "            \n",
    "    # Empty df to prevent the old values appear on the next run\n",
    "    empty_df(df)\n",
    "    \n",
    "    coef = np.abs(coef)\n",
    "    coef_ols = np.abs(coef_ols)\n",
    "    return coef, coef_ols, error   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58aa927",
   "metadata": {},
   "source": [
    "# Constant Chlorine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9814d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### < Code for Constant Chlorine > ###\n",
    "\n",
    "# NOTE: concentration = const_C\n",
    "def regression_for_CT(df, CT_to_use):\n",
    "    coef_list = []\n",
    "    if (df[\"ln 10 reduction\"].isnull().sum() != 0):\n",
    "        data = df.dropna(subset = ['ln 10 reduction'])\n",
    "    else: \n",
    "        data = df.copy()\n",
    "    \n",
    "    x = np.array(data[\"CT_values\"][0:CT_to_use])\n",
    "    y = np.array(data['ln 10 reduction'][0:CT_to_use])\n",
    "    \n",
    "    df_xy = pd.DataFrame({\"x_val\": x, \"y_val\": y})\n",
    "    smOLS_reault = sm.OLS(endog= df_xy[['y_val']], exog= df_xy[['x_val']].assign(intercept=0)).fit()\n",
    "\n",
    "    k_value_OLS = smOLS_reault.params[0]\n",
    "    std_erro_OLS = smOLS_reault.bse[0]\n",
    "    \n",
    "    A = np.vstack([x, np.ones(len(x))]).T # Add one to x and drop the ones later\n",
    "    k_value = float(np.linalg.lstsq(A[:, :-1], y)[0]) # use [0] to just grab the k value coefs\n",
    "    \n",
    "    df.iloc[0:CT_to_use, :]\n",
    "    \n",
    "    return k_value, k_value_OLS, std_erro_OLS # (2/19/2023) Also return k_value_OLS, std_erro_OLS here \n",
    "\n",
    "def constant_chlorine(df, concentration, CT_to_use):\n",
    "    df[\"CT_values\"] = df[\"Time (min)\"] * concentration\n",
    "    df = sort_row_according_to_Time(df) # Sort Time column\n",
    "    convert_to_ln(df)\n",
    "    \n",
    "    # Visualize the linear regression\n",
    "    k_value, k_value_OLS, std_erro_OLS = regression_for_CT(df, CT_to_use)\n",
    "    k_value = np.abs(k_value)\n",
    "    k_value_OLS = np.abs(k_value_OLS)\n",
    "\n",
    "    # Empty df to prevent the old values appear on the next run\n",
    "    empty_df(df)\n",
    "    \n",
    "    return k_value, k_value_OLS, std_erro_OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8f051",
   "metadata": {},
   "source": [
    "# Given CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c54559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Given_CT(df, CT_to_use):    \n",
    "    convert_to_ln(df)\n",
    "\n",
    "    # Sort by CT columns\n",
    "    df = df.sort_values(by = \"CT_values\", ascending = True)\n",
    "    # display(df) # testing\n",
    "   \n",
    "    # Visualize the linear regression\n",
    "    k_value, k_value_OLS, std_erro_OLS = regression_for_CT(df, CT_to_use)\n",
    "    k_value = np.abs(k_value)\n",
    "    k_value_OLS = np.abs(k_value_OLS)\n",
    "\n",
    "    # Empty df to prevent the old values appear on the next run\n",
    "    empty_df(df)\n",
    "    \n",
    "    return k_value, k_value_OLS, std_erro_OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f8315",
   "metadata": {},
   "source": [
    "# Applications Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161c19ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Method</th>\n",
       "      <th>Coef_np</th>\n",
       "      <th>Coef_OLS</th>\n",
       "      <th>Standard_Error</th>\n",
       "      <th>Data_Points_Used</th>\n",
       "      <th>Diff</th>\n",
       "      <th>larger_than</th>\n",
       "      <th>smaller_than</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"32-1\"</td>\n",
       "      <td>3</td>\n",
       "      <td>179.923163</td>\n",
       "      <td>179.923163</td>\n",
       "      <td>8.917193</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"32-2\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1.493117</td>\n",
       "      <td>1.493117</td>\n",
       "      <td>0.116947</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample_ID  Method     Coef_np    Coef_OLS  Standard_Error  Data_Points_Used  \\\n",
       "0    \"32-1\"       3  179.923163  179.923163        8.917193                22   \n",
       "1    \"32-2\"       3    1.493117    1.493117        0.116947                21   \n",
       "\n",
       "   Diff  larger_than  smaller_than  \n",
       "0     0          0.0           0.0  \n",
       "1     0          0.0           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R1path = '/Users/mirac/Desktop/Chlorine_Project/August 18 Chlorine Review Paper/Chlorine_Review_Revisions/1-Revisions_Inactivation_Rate_Data_R1.xlsx'\n",
    "R2path = '/Users/mirac/Desktop/Chlorine_Project/August 18 Chlorine Review Paper/Chlorine_Review_Revisions/2-Revisions_Inactivation_Rate_Data_R2.xlsx'\n",
    "\n",
    "#insert sheet name here\n",
    "sheet_name = \"Paper_32\"\n",
    "summ = results(R2path, sheet_name)\n",
    "greaterSmallerCols = [col for col in summ.columns if \"_than\" in col]\n",
    "summ[greaterSmallerCols] = summ[greaterSmallerCols].fillna(value=0)\n",
    "display(summ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb45a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53190839",
   "metadata": {},
   "source": [
    "# Combine Every Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f47f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "initalValPath = '/Users/mirac/Desktop/Chlorine_Project/August 18 Chlorine Review Paper/Chlorine_Review_Revisions/Virus_Data - Final_Experimental_Data.csv'\n",
    "numArray = np.arange(1, 82, 1)\n",
    "# finalTable = pd.DataFrame(columns = ['Sample_ID', 'Method', 'Coef_np', 'Coef_OLS', 'Standard_Error', 'Diff', 'Data_Points_Used'])\n",
    "finalTable_R1 = pd.DataFrame()\n",
    "\n",
    "path_to_use = R1path # Change path here\n",
    "\n",
    "for num in numArray:\n",
    "    sheetName = \"Paper_\" + str(num)\n",
    "    summ = results(path_to_use, sheetName) \n",
    "    \n",
    "    # Rename greater_than to largr_than\n",
    "    if \"greater_than\" in summ.columns:\n",
    "        summ.rename(columns = {'greater_than': 'larger_than'}, inplace=True)\n",
    "\n",
    "    greaterSmallerCols = [col for col in summ.columns if \"_than\" in col]\n",
    "    summ[greaterSmallerCols] = summ[greaterSmallerCols].fillna(value=0)\n",
    "    finalTable_R1 = pd.concat([finalTable_R1, summ], axis = 0)\n",
    "    # print(\"Paper \", num, \": Done\") # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4a492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTable_R2 = pd.DataFrame()\n",
    "path_to_use = R2path # Change path here\n",
    "\n",
    "for num in numArray:\n",
    "    sheetName = \"Paper_\" + str(num)\n",
    "    summ = results(path_to_use, sheetName) \n",
    "    \n",
    "    # Rename greater_than to largr_than\n",
    "    if \"greater_than\" in summ.columns:\n",
    "        summ.rename(columns = {'greater_than': 'larger_than'}, inplace=True)\n",
    "\n",
    "    greaterSmallerCols = [col for col in summ.columns if \"_than\" in col]\n",
    "    summ[greaterSmallerCols] = summ[greaterSmallerCols].fillna(value=0)\n",
    "    finalTable_R2 = pd.concat([finalTable_R2, summ], axis = 0)\n",
    "    # print(\"Paper \", num, \": Done\") # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a00cd9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeQuotes(x):\n",
    "    return x.replace('\"', \"\")\n",
    "\n",
    "finalTable_R1['Sample_ID'] = finalTable_R1['Sample_ID'].apply(removeQuotes)\n",
    "finalTable_R2['Sample_ID'] = finalTable_R2['Sample_ID'].apply(removeQuotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6d86e",
   "metadata": {},
   "source": [
    "# Combine Mira and Kaming Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e65227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sample_ID', 'Method_R1', 'Coef_np_R1', 'Coef_OLS_R1',\n",
       "       'Standard_Error_R1', 'Data_Points_Used_R1', 'Diff_R1', 'Data_Points_R1',\n",
       "       'smaller_than_R1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTable_R1_2 = finalTable_R1.copy()\n",
    "finalTable_R1_2 = finalTable_R1_2[['Sample_ID', 'Method', 'Coef_np', 'Coef_OLS', 'Standard_Error',\n",
    "       'Data_Points_Used', 'Diff', 'Data_Points', 'smaller_than']]\n",
    "keep_same = {'Sample_ID'}\n",
    "finalTable_R1_2.columns = ['{}{}'.format(c, '' if c in keep_same else '_R1')\n",
    "               for c in finalTable_R1_2.columns]\n",
    "\n",
    "finalTable_R1_2.columns\n",
    "\n",
    "#finalTableMira_2.to_csv('finalTable_R1_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4610ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTable_R2_2 = finalTable_R2.copy()\n",
    "finalTable_R2_2 = finalTable_R2_2[['Sample_ID', 'Method', 'Coef_np', 'Coef_OLS', 'Standard_Error',\n",
    "       'Data_Points_Used', 'Diff', 'smaller_than', 'larger_than']]\n",
    "finalTable_R2_2.columns = ['{}{}'.format(c, '' if c in keep_same else '_R2')\n",
    "               for c in finalTable_R2_2.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d1e6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_both_reviewers = finalTable_R1_2.merge(finalTable_R2_2, on = \"Sample_ID\", how = 'left')\n",
    "\n",
    "dataset_both_reviewers.to_csv('4-kinetics_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3c117",
   "metadata": {},
   "source": [
    "# Compare with initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2189a7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(636, 3)\n"
     ]
    }
   ],
   "source": [
    "initial = pd.read_csv(initalValPath)[['kobs_mira (removed > and <)', 'kobs_kaming (removed > and <)', 'Sample ID']]\n",
    "initial.dropna(subset= ['kobs_mira (removed > and <)', 'kobs_kaming (removed > and <)'], inplace=True)\n",
    "initial.columns = ['init_mira', 'init_kaming', 'Sample_ID']\n",
    "print(initial.shape)\n",
    "\n",
    "# Data points used for modeling\n",
    "data_used_model = pd.read_csv(initalValPath)\n",
    "data_used_modeling = data_used_model[data_used_model['data_for_modeling']==1]['Sample ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42739e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path used: /Users/mirac/Desktop/Chlorine_Project/August 18 Chlorine Review Paper/Chlorine_Review_Revisions/2-Revisions_Inactivation_Rate_Data_R2.xlsx\n",
      "There are 0 rows with k value differences > 10^-6.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Method</th>\n",
       "      <th>Coef_np</th>\n",
       "      <th>Coef_OLS</th>\n",
       "      <th>Standard_Error</th>\n",
       "      <th>Data_Points_Used</th>\n",
       "      <th>Diff</th>\n",
       "      <th>larger_than</th>\n",
       "      <th>Data_Points</th>\n",
       "      <th>smaller_than</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>init_mira</th>\n",
       "      <th>init_kaming</th>\n",
       "      <th>CompareInit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sample_ID, Method, Coef_np, Coef_OLS, Standard_Error, Data_Points_Used, Diff, larger_than, Data_Points, smaller_than, Unnamed: 20, Unnamed: 19, Unnamed: 18, Unnamed: 24, Unnamed: 21, Unnamed: 26, Unnamed: 25, Unnamed: 27, Unnamed: 23, Unnamed: 22, Unnamed: 28, init_mira, init_kaming, CompareInit]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_init = finalTable_R1.merge(initial, on = \"Sample_ID\", how = 'left')\n",
    "\n",
    "diffCheck = merged_init['Diff'] != 0\n",
    "if (diffCheck.any()):\n",
    "    raise ValueError(\"Column 'Diff' is non-zero\")\n",
    "\n",
    "if (path_to_use == R1path):\n",
    "    init_col = 'init_kaming'\n",
    "elif (path_to_use == R2path):\n",
    "    init_col = 'init_mira'\n",
    "else:\n",
    "    raise ValueError(\"ERROR: Unknow file path!\")\n",
    "print(f\"Path used: {path_to_use}\")\n",
    "\n",
    "merged_init['CompareInit'] = np.abs(np.abs(merged_init['Coef_np']) - np.abs(merged_init[init_col]))\n",
    "merged_init_compare = merged_init[merged_init['CompareInit'] > (10**-6)] # Set threshold at 10^(-6)\n",
    "\n",
    "merged_init_compare = merged_init_compare[merged_init_compare['larger_than'] == 0]\n",
    "merged_init_compare = merged_init_compare[merged_init_compare[\"Sample_ID\"].isin(data_used_modeling)]\n",
    "print(f\"There are {merged_init_compare.shape[0]} rows with k value differences > 10^-6.\")\n",
    "\n",
    "merged_init_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e888ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae7d9cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Method</th>\n",
       "      <th>Coef_np</th>\n",
       "      <th>Coef_OLS</th>\n",
       "      <th>Standard_Error</th>\n",
       "      <th>Data_Points_Used</th>\n",
       "      <th>Diff</th>\n",
       "      <th>larger_than</th>\n",
       "      <th>Data_Points</th>\n",
       "      <th>smaller_than</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>init_mira</th>\n",
       "      <th>init_kaming</th>\n",
       "      <th>CompareInit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sample_ID, Method, Coef_np, Coef_OLS, Standard_Error, Data_Points_Used, Diff, larger_than, Data_Points, smaller_than, Unnamed: 20, Unnamed: 19, Unnamed: 18, Unnamed: 24, Unnamed: 21, Unnamed: 26, Unnamed: 25, Unnamed: 27, Unnamed: 23, Unnamed: 22, Unnamed: 28, init_mira, init_kaming, CompareInit]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for specific paper\n",
    "paper = 21\n",
    "merged_init_compare[merged_init_compare['Sample_ID'].str.startswith(str(paper)+ \"-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baa2df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Sample_ID, Coef_np, init_kaming, CompareInit]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Search for specificpaper\n",
    "paper = 21\n",
    "merged_selection = merged_init_compare[merged_init_compare['Sample_ID'].str.startswith(str(paper)+ \"-\")]\n",
    "print(merged_selection[['Sample_ID','Coef_np','init_kaming','CompareInit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877de410",
   "metadata": {},
   "source": [
    "### Sort the k value differences in a descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7834b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Method</th>\n",
       "      <th>Coef_np</th>\n",
       "      <th>Coef_OLS</th>\n",
       "      <th>Standard_Error</th>\n",
       "      <th>Data_Points_Used</th>\n",
       "      <th>Diff</th>\n",
       "      <th>larger_than</th>\n",
       "      <th>Data_Points</th>\n",
       "      <th>smaller_than</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>init_mira</th>\n",
       "      <th>init_kaming</th>\n",
       "      <th>CompareInit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sample_ID, Method, Coef_np, Coef_OLS, Standard_Error, Data_Points_Used, Diff, larger_than, Data_Points, smaller_than, Unnamed: 20, Unnamed: 19, Unnamed: 18, Unnamed: 24, Unnamed: 21, Unnamed: 26, Unnamed: 25, Unnamed: 27, Unnamed: 23, Unnamed: 22, Unnamed: 28, init_mira, init_kaming, CompareInit]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "diff_df = merged_init_compare.sort_values(by = 'CompareInit', ascending = False)\n",
    "print(diff_df.shape)\n",
    "\n",
    "diff_df[diff_df['CompareInit'] > 10**(-6)].shape\n",
    "diff_df\n",
    "\n",
    "# Paper 19 not included in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2499c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f3c967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tailing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50f9e0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sample_ID', 'Method', 'Coef_np', 'Coef_OLS', 'Standard_Error',\n",
       "       'Data_Points_Used', 'Diff', 'larger_than', 'Data_Points',\n",
       "       'smaller_than', 'Unnamed: 20', 'Unnamed: 19', 'Unnamed: 18',\n",
       "       'Unnamed: 24', 'Unnamed: 21', 'Unnamed: 26', 'Unnamed: 25',\n",
       "       'Unnamed: 27', 'Unnamed: 23', 'Unnamed: 22', 'Unnamed: 28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTable_R1.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
